{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro To Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![algoritmMachineLearn](algoritmMachineLearn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Naive Bayes o clasificador 'ingenuo' de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nuestro clasificador es \"Supervised\" tendremos una fase de entrenamiento donde tendremos que decirle claramente \"Mira aquí tengo 80 cartas, estas 50 son de Juana y estas 30 son de Pepe\". Y a partir de ahí el clasificador realizará predicciones basada en ese entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPERVISED CLASSIFIERS\n",
    "\n",
    "Los \"Supervised classifiers\" se basan en distintos algoritmos matemático-estadísticos. Algunos famosos son:\n",
    "\n",
    "   - Naive Bayes\n",
    "   - K nearest neighbors\n",
    "   - SVC (Support Vector Classifiers)\n",
    "   - Decision Trees\n",
    "   - Ensemble methods\n",
    "\n",
    "\n",
    "El que vamos a ver hoy es Naive Bayes o clasificador \"ingenuo\" de Bayes\n",
    "\n",
    "Este clasificador se basa en el teorema de Bayes y se denomina ingenuo porque asume independencia en ciertas características de los datos a la hora de realizar la predicción.\n",
    "\n",
    "Si seguimos el ejemplo de las cartas, Naive Bayes, tendrá en cuenta aspectos como la frecuencia con la que se repiten ciertos términos, pero obviará otras características como el orden de cada una de las palabras, ya que asume independencia en esa variable.\n",
    "\n",
    "Teniendo ciertos elementos clasificados, un nuevo elemento tendrá la siguiente probabilidad de pertenecer a cierto grupo:\n",
    "\n",
    "$p(A|F_{1}...F_{n})$\n",
    "\n",
    "\n",
    "Que aplicando el Teorema de Bayes en el que se basa este clasificador:\n",
    "\n",
    "![eq2](eq2.png)\n",
    "\n",
    "Y que suele ponerse de manera conceptual como:\n",
    "\n",
    "![eq3](eq3.png)\n",
    "\n",
    "Por tanto la probabilidad de que una carta sea de Juana dada una característica concreta (posterior), es igual a multiplicar la probabilidad de escritura de Juana (prior) por la probabilidad de que se dé esa característica en una carta de Juana(probability) dividido por la probabilidad de que aparezca esa característica en cualquier carta (normalizer)\n",
    "\n",
    "![eq4](eq4.png)\n",
    "\n",
    "Al estar normalizado podemos asegurar por tanto que la probabilidad de Pepe es:\n",
    "\n",
    "![eq5](eq5.png)\n",
    "\n",
    "Obviamente estamos considerando que la carta sólo puede ser de Juana o de Pepe en este espacio.\n",
    "\n",
    "Basándonos en este algoritmo vamos a crear un \"Supervised Classifier\" vamos a entrenarlo y vamos a hacer algunas predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es instalar sckit-learn con el comando\n",
    "\n",
    "    !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Exportamos los datasets de ejemplo de sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "#Y la funcion para dividir el dataset\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de data_train 100\n",
      "Tamaño de label_train 100\n"
     ]
    }
   ],
   "source": [
    "##Dataset length == 100\n",
    "##Con la funcion make_classification creamos un array\n",
    "data_train, labels_train = make_classification(n_samples=100, n_features=10)\n",
    "print(\"Tamaño de data_train\",len(data_train))\n",
    "print(\"Tamaño de label_train\",len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dividir el dataset en datos de entrenamiento y datos de test\n",
    "#Sera el 90% para entrenamiento y 10% para test\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data_train,labels_train,test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de data_train 90\n",
      "Tamaño de label_train 90\n",
      "Tamaño de data_test 10\n",
      "Tamaño de labels_test 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de data_train\",len(data_train))\n",
    "print(\"Tamaño de label_train\",len(labels_train))\n",
    "print(\"Tamaño de data_test\",len(data_test))\n",
    "print(\"Tamaño de labels_test\",len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importamos el algoritmo que utilizaremos\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creamos el clasificador basao en Naive Bayes\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando:\n",
      "[1 1 1 1 1 1 0 0 0 0]\n",
      "[1 0 1 1 1 1 0 0 0 0]\n",
      "Podemos ver que el tiene un alto porcentaje de prediccion.\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el clasificador\n",
    "#Le pasaremos 90 textos(90% del dataset, que es el dessignado para entrenamiento)\n",
    "#Y 90 etiquetas\n",
    "clf.fit(data_train, labels_train)\n",
    "#Hacer una prediccion con los datos designados a testing\n",
    "predictions = clf.predict(data_test)\n",
    "#Mostrando la prediccion\n",
    "print(\"Comparando:\")\n",
    "#predicciones \n",
    "print(predictions)\n",
    "#Lo que es realmente\n",
    "print(labels_test)\n",
    "print(\"Podemos ver que el tiene un alto porcentaje de prediccion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de exactitud es de 0.9 o visto en porcentaje 90.0%\n"
     ]
    }
   ],
   "source": [
    "#Si queremos ver esto en numeros que midan el porcentaje\n",
    "#de presicion en nuestra prediccion(exactitud)\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Exactitud entre predicciones y lo que realmente es\n",
    "acc = accuracy_score(predictions, labels_test)\n",
    "print(\"El porcentaje de exactitud es de {} o visto en porcentaje {}%\".format(acc,acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para que arroje datos y predicciones diferentes podemos ejecutar todo el codigo de nuevo en la barra en _Kernel_ desplegamos y damos click en _Restart and Run All_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para mas detalle este ejemplo esta explicado en YT aca\n",
    "[Naive Bayes](https://www.youtube.com/watch?v=4MHSCz9hguM&index=1&list=PLNUuXUGwh9WxYSNs8QT5fYB5usZiDdylJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
